{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stephanie_Eordanidis_CIS700_Midterm_NLP_Attack.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "_RTasmaUQsnX"
      },
      "source": [
        "# Midterm - \"Natural Language Processing Attacks\"\n",
        "\n",
        "Stephanie Eordanidis\n",
        "\n",
        "Syracuse University : College of Engineering & Computer Science\n",
        "\n",
        "223 Link Hall, Syracuse, NY 13244\n",
        "\n",
        "*sleordan@syr.edu*\n",
        "\n",
        "CIS 700 Machine Learning and Security\n",
        "\n",
        "05/19/2021\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "2saP1Da3Qsnf"
      },
      "source": [
        "## Theme:\n",
        " “Adversarial Text Generation: Adversarial Machine Learning Applications in Text Analysis”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "M443L_l7Qsng"
      },
      "source": [
        "## Purpose:\n",
        "The purpose of this lab is to run a project that relates to the miderm paper topics. This lab demonstrates \"Natural Language Processing Attacks\" topic using the selected project and indicated recepie and models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Bsrl-QKhQsnh"
      },
      "source": [
        "## Project:\n",
        "TextAttack is the name of the project selected. TextAttack is an extensive python based framework for adversarial attacks, data augmentation, and model training in NLP. This framework serves as a great benchmarking tool that aids researchers in testign a multitude attacks with varying manipulation techniques and models employed while allowing for a common baseline for comparisions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "YmXaOJ8AQsni"
      },
      "source": [
        "##(Hard/Soft)ware:\n",
        "**Google Colaboratory**\t\thttps://colab.research.google.com/\n",
        "\n",
        "**GPU**                     Python 3 Google Compute Engine backend\n",
        "\n",
        "**Github**                  https://github.com/QData/TextAttack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "QGtxblBCQsni"
      },
      "source": [
        "## Resources:\n",
        "**Original Source:** \t\thttps://github.com/QData/TextAttack\n",
        "\n",
        "> *Note:* No code was needed to be modified, lab was run simply by cloning from github resource location"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "kolVF4c9Qsnj"
      },
      "source": [
        "## Data:\n",
        "The data for the selected project the SNLI data set avaialble through text attack.\n",
        "\n",
        "*SNLI*: https://github.com/huggingface/datasets/tree/master/datasets/snli\n",
        "\n",
        "*Description:* The Stanford Natural Language Inference (SNLI) Corpus is a set of data containing well over 570k human-written English sentence pairs, each labled for balance of classification wihtin this data repository\n",
        "\n",
        "*Data Fields (3)*\n",
        "* premise: a string used to determine the truthfulness of the hypothesis\n",
        "\n",
        "* hypothesis: a string that may be true, false, or whose truth conditions may not be knowable when compared to the premise\n",
        "\n",
        "* label: an integer whose value may be either 0, indicating that the hypothesis entails the premise, 1, indicating that the premise and hypothesis neither entail nor contradict each other, or 2, indicating that the hypothesis contradicts the premise.\n",
        "    \n",
        "To take a sneek peek at the data set and its characteristics, will will run the following command:\n",
        "\n",
        "```\n",
        "!textattack peek-dataset --dataset-from-huggingface snli\n",
        "```\n",
        "\n",
        "As we see from the results, there are 550,152 samples provided with this data set and overall should be a simple set to use for testing. However, it is noted that there are some samples missing a lable, so those will be disregarded via an argument later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKr9gTg8qAuw",
        "outputId": "b28b79b4-b83b-4b71-969e-4d1f668d3135"
      },
      "source": [
        "!textattack peek-dataset --dataset-from-huggingface snli"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset snli (/root/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b)\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94msnli\u001b[0m, split \u001b[94mtrain\u001b[0m.\n",
            "\u001b[34;1mtextattack\u001b[0m: Number of samples: \u001b[94m550152\u001b[0m\n",
            "\u001b[34;1mtextattack\u001b[0m: Number of words per input:\n",
            "\u001b[34;1mtextattack\u001b[0m: \ttotal:   \u001b[94m11150480\u001b[0m\n",
            "\u001b[34;1mtextattack\u001b[0m: \tmean:    \u001b[94m20.27\u001b[0m\n",
            "\u001b[34;1mtextattack\u001b[0m: \tstd:     \u001b[94m6.95\u001b[0m\n",
            "\u001b[34;1mtextattack\u001b[0m: \tmin:     \u001b[94m4\u001b[0m\n",
            "\u001b[34;1mtextattack\u001b[0m: \tmax:     \u001b[94m112\u001b[0m\n",
            "\u001b[34;1mtextattack\u001b[0m: Dataset lowercased: \u001b[94mFalse\u001b[0m\n",
            "\u001b[34;1mtextattack\u001b[0m: First sample:\n",
            "Premise: A teenager with a purple bandanna around his neck plays the electric guitar and screams into a microphone.\n",
            "Hypothesis: The teenager is playing the guitar. \n",
            "\n",
            "\u001b[34;1mtextattack\u001b[0m: Last sample:\n",
            "Premise: A rickshaw operator waiting for his next costumer.\n",
            "Hypothesis: A rickshaw operator is driving his last customer. \n",
            "\n",
            "\u001b[34;1mtextattack\u001b[0m: Found 4 distinct outputs.\n",
            "\u001b[34;1mtextattack\u001b[0m: Most common outputs:\n",
            "\t 0      (183416)\n",
            "\t 2      (183187)\n",
            "\t 1      (182764)\n",
            "\t -1     (785)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "BlSdA9AHQsnk"
      },
      "source": [
        "## Setup:\n",
        "Due to the heft of processor/gpu usage, it was deemed necessary to run the project in the Google Colaboratory. Original attempt to run was done via Pycharm IDE Professional Edition with Anaconda derived environments, however this proved too great of a strain on the accessible workstation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "s8H8-PlvQsnk"
      },
      "source": [
        "### Step 1\n",
        "A new Google Colaboratory workspace was setup, titled “Stephanie_Eordanidis_CIS700_Midterm_NLP_Attack”. This workspace was run using the hosted runtime environment. This document is the current document being read.\n",
        "\n",
        "In order to run against provided code base, it was necessary to sync the colab workspace the github repository files as follows\n",
        "\n",
        "```\n",
        "!git clone https://$GITHUB_AUTH@github.com/QData/TextAttack\n",
        "```\n",
        "\n",
        "Running this command from the first cell in the workbook syncs the drive to the github repo location of project location"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7jPNtvoeQsnl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54dbd0f8-d2b4-4bb6-9611-c61007da819f"
      },
      "source": [
        "!git clone https://$GITHUB_AUTH@github.com/QData/TextAttack"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'TextAttack'...\n",
            "remote: Enumerating objects: 18459, done.\u001b[K\n",
            "remote: Counting objects: 100% (389/389), done.\u001b[K\n",
            "remote: Compressing objects: 100% (285/285), done.\u001b[K\n",
            "remote: Total 18459 (delta 205), reused 206 (delta 104), pack-reused 18070\u001b[K\n",
            "Receiving objects: 100% (18459/18459), 24.02 MiB | 35.03 MiB/s, done.\n",
            "Resolving deltas: 100% (13763/13763), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "aJ-ge5jqQsno"
      },
      "source": [
        "### Step 2\n",
        "Now it was necessary to install the took via the following command:\n",
        "```\n",
        "            !pip install textattack\n",
        "```\n",
        "Running this command from the next cell in the workbook installed the necessary libraries and at specified versions for the project as well as other reqs and needed setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "MO2DlrxDQsno"
      },
      "source": [
        "!pip install textattack"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "-Rp_zaP5Qsnp"
      },
      "source": [
        "### Step 3\n",
        "Now it is time to run the application. \n",
        "\n",
        "For help on how to use the tool, the folling commands can be used:\n",
        "\n",
        "```\n",
        "textattack --help                      <general information about all commands>\n",
        "\n",
        "textattack attack --help               <information on a specific command>\n",
        "```\n",
        "\n",
        "This is the base for attack commands:\n",
        "```\n",
        "!python3 textattack attack\n",
        "```\n",
        "\n",
        "This argument runs the attack recipe, specify an attack to run as seen below:\n",
        "```\n",
        "--recipe textfooler\n",
        "```\n",
        "\n",
        "This argument runs the training model, specify model to run as seen below:\n",
        "```\n",
        "--model distilbert-base-cased\n",
        "```\n",
        "\n",
        "For this lab, our attention is ono the textfooler attack receipie with bert model training.\n",
        "\n",
        "additional args that will be utilized are \n",
        "```\n",
        "--dataset snli                \\ # indicate dataset, in this case SNLI\n",
        "--max-length 128              \\ # Set maximum sequence length to 128\n",
        "--batch-size 128              \\ # And a batch size of 128\n",
        "--epochs 2                    \\ # Run for 2 epochs\n",
        "--allowed-labels 0 1 2        \\ # And only allow labels 0, 1, 2 \n",
        "(filter out missing noticed in data set peeking earlier)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "wbTurK39Qsnq"
      },
      "source": [
        "## Recipe and Models\n",
        "For this report, we will focus on the TextFooler attack using BERT models as seen in related literature review.\n",
        "TextFooler is a simplified word transformation attack developed by Jin et al. (2019). This study used a number of variants such as constraints and classifier methods. BERT modeling was selected due to the original study metrics. In Jin et al. (2019), the BERT model boasted the highest original accuracy scoring of all implemented and tested. For this lab, it is desired to run TextFooler against BERT to see if that is so."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "KkTxDWRTQsnq"
      },
      "source": [
        "## Training\n",
        "\n",
        "We will first train our model with the following paramters:\n",
        "\n",
        "```\n",
        "--model distilbert-base-cased\n",
        "--dataset snli \n",
        "--epoch 2                     - due to time constraints used 2\n",
        "--max-length 128 \n",
        "--batch-size 128               -due to memory constraints cannot use > 128 \n",
        "--allowed-labels 0 1 2\n",
        "\n",
        "```\n",
        "It was noted that Loss decreased over time, reducing to < 0.5,indicating training with the specified parameters generated a better model.\n",
        "\n",
        "Model values on training completion: \n",
        "\n",
        "Epoch 1\n",
        "* Loss 0.48206932397189883: 100% 4292/4292 [1:35:03<00:00,  1.33s/it]\n",
        "* Train accuracy: 80.78206372060936%\n",
        "* Eval accuracy: 86.49664702296282%\n",
        "\n",
        "Epoch 2\n",
        "* Loss 0.48206932397189883: 100% 4292/4292 [1:35:03<00:00,  1.33s/it]\n",
        "* Train accuracy: 80.78206372060936%\n",
        "* Eval accuracy: 86.49664702296282%\n",
        "\n",
        "This will prepare the data for use with attack later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "p0dEpH0EQsnr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf91b2c6-d6be-4c2f-ae0f-5ce96f2117c5"
      },
      "source": [
        "!textattack train --model distilbert-base-cased --dataset snli --max-length 128 --batch-size 128 --epochs 2 --allowed-labels 0 1 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34;1mtextattack\u001b[0m: WARNING: TextAttack's model training feature is in beta. Please report any issues on our Github page, https://github.com/QData/TextAttack/issues.\n",
            "\u001b[34;1mtextattack\u001b[0m: Writing logs to /usr/local/lib/python3.7/dist-packages/outputs/training/distilbert-base-cased-snli-2021-05-01-22-20-47-160259/log.txt.\n",
            "Downloading: 3.82kB [00:00, 3.69MB/s]       \n",
            "Downloading: 1.90kB [00:00, 1.95MB/s]     \n",
            "Downloading and preparing dataset snli/plain_text (download: 90.17 MiB, generated: 65.51 MiB, post-processed: Unknown size, total: 155.68 MiB) to /root/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b...\n",
            "Downloading: 100% 1.93k/1.93k [00:00<00:00, 1.54MB/s]\n",
            "Downloading: 100% 1.26M/1.26M [00:00<00:00, 54.3MB/s]\n",
            "Downloading: 100% 65.9M/65.9M [00:01<00:00, 65.6MB/s]\n",
            "Downloading: 100% 1.26M/1.26M [00:00<00:00, 55.4MB/s]\n",
            "Dataset snli downloaded and prepared to /root/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b. Subsequent calls will reuse this data.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94msnli\u001b[0m, split \u001b[94mtrain\u001b[0m.\n",
            "Reusing dataset snli (/root/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b)\n",
            "Reusing dataset snli (/root/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b)\n",
            "Reusing dataset snli (/root/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b)\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94msnli\u001b[0m, split \u001b[94mvalidation\u001b[0m.\n",
            "\u001b[34;1mtextattack\u001b[0m: Loaded dataset. Found: 3 labels: [0, 1, 2]\n",
            "\u001b[34;1mtextattack\u001b[0m: Loading transformers AutoModelForSequenceClassification: distilbert-base-cased\n",
            "Downloading: 100% 411/411 [00:00<00:00, 546kB/s]\n",
            "Downloading: 100% 263M/263M [00:04<00:00, 61.7MB/s]\n",
            "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Downloading: 100% 213k/213k [00:00<00:00, 15.8MB/s]\n",
            "Downloading: 100% 436k/436k [00:00<00:00, 22.3MB/s]\n",
            "Downloading: 100% 29.0/29.0 [00:00<00:00, 28.1kB/s]\n",
            "\u001b[34;1mtextattack\u001b[0m: Training model across 1 GPUs\n",
            "2021-05-01 22:21:35.777365: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[34;1mtextattack\u001b[0m: Wrote original training args to /usr/local/lib/python3.7/dist-packages/outputs/training/distilbert-base-cased-snli-2021-05-01-22-20-47-160259/train_args.json.\n",
            "\u001b[34;1mtextattack\u001b[0m: ***** Running training *****\n",
            "\u001b[34;1mtextattack\u001b[0m: \tNum examples = 549367\n",
            "\u001b[34;1mtextattack\u001b[0m: \tBatch size = 128\n",
            "\u001b[34;1mtextattack\u001b[0m: \tMax sequence length = 128\n",
            "\u001b[34;1mtextattack\u001b[0m: \tNum steps = 8582\n",
            "\u001b[34;1mtextattack\u001b[0m: \tNum epochs = 2\n",
            "\u001b[34;1mtextattack\u001b[0m: \tLearning rate = 2e-05\n",
            "Loss 0.8546324043930648:   4% 168/4292 [03:30<1:28:37,  1.29s/it]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpYlb1Ipnglp"
      },
      "source": [
        "## Evaluation\n",
        "In training, we tuned our `distilbert-base-cased` model for 3 epochs. We will now evaluate it using `textattack eval` function. All that is necessary is to indicate the path to the pretrained model to `--model`, along with the number of evaluation samples. `textattack eval` will automatically load the evaluation data from training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QojM8dXaBpzf"
      },
      "source": [
        "%cp /usr/local/lib/python3.7/dist-packages/outputs/training /output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jsHmC_Snglp"
      },
      "source": [
        "!textattack eval --num-examples 10 --model /usr/local/lib/python3.7/dist-packages/outputs/training/distilbert-base-cased-snli-2021-05-01-18-01-22-130746"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYnFdaucwhuR"
      },
      "source": [
        "## Attack\n",
        "\n",
        "After we have trained and evaluated our model, we will now be able to finally perform our attack. As indicated periously in this lab, we will be using the \"TextFooler\" attack recipe developed under Jin et al, (2019)\n",
        "\n",
        "> *Note:*  Due to time constrains this lab will only print out 10 examples and their perpetuations if the attack worked. If wanted, can increase this number to see more samples. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFUSd8BKwWz9"
      },
      "source": [
        "!textattack attack --recipe textfooler --num-examples 10 --model /usr/local/lib/python3.7/dist-packages/outputs/training/distilbert-base-cased-snli-2021-05-01-18-01-22-130746"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sx5S7RXSwW0A"
      },
      "source": [
        "After the attack it appears the model sucess rate was \n",
        "\n",
        "Looks like our model was 86.8% successful, meaning that TextAttack attacked the model with 868 examples (since the attack won't run if an example is originally mispredicted). The attack success rate was 88.7%, meaning that TextFooler failed to find an adversarial example only 11.3% of the time.\n",
        "\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "TextFooler is a powerful attack method aginast modern day natural language processing models and adversarial machine learning samples. Even in this small test, this lab demonstrated the capabilities of this word substitution attack method. Had memory not been an issue, larger batch sizes and extended epoch would likely have yeilded an even greater result set. More research into defenses against NLP attacks will be necessary in the future, provided the focus broaded to the textual context domain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "zGfiU7ujQsnw"
      },
      "source": [
        "## Reference\n",
        "[1] QData - Text Attack. https://github.com/QData/TextAttack\n",
        "\n",
        "[2] Morris, J. X., Lifland, E., Yoo, J. Y., Grigsby, J., Jin, D., & Qi, Y. (2020, April 29). TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and Adversarial Training in NLP. ArXiv.Org. https://arxiv.org/abs/2005.05909 \n",
        "\n",
        "[3] Jin, D., Jin, Z., Zhou, J. T., & Szolovits, P. (2019, July 27). Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment. ArXiv.Org. https://arxiv.org/abs/1907.11932\n",
        "\n",
        "[4] Huggingface Datasets: https://github.com/huggingface/datasets/tree/master/datasets/snli\n",
        "\n",
        "[5] Stanford NLP : https://nlp.stanford.edu/projects/snli/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "9irmoejZQsnw"
      },
      "source": [
        "#PDF/HTML conversion of notebook\n",
        "!apt-get install texlive texlive-xetex texlive-latex-extra pandoc\n",
        "!pip install pypandoc\n",
        "!jupyter nbconvert --to PDF \"Stephanie_Eordanidis_CIS700_Midterm_NLP_Attack.ipynb\"\n",
        "!jupyter nbconvert --to HTML \"Stephanie_Eordanidis_CIS700_Midterm_NLP_Attack.ipynb\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}