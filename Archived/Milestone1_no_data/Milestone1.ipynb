{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o49pPlnCRdob"
   },
   "source": [
    "#Milestone1\n",
    "Stephanie Eordanidis.\n",
    "Ravjot Sachdev,\n",
    "Jackson Taber\n",
    "\n",
    "Syracuse University : College of Engineering & Computer Science\n",
    "\n",
    "223 Link Hall, Syracuse, NY 13244\n",
    "\n",
    "*sleordan@syr.edu*\n",
    "\n",
    "CIS 700 Machine Learning and Security\n",
    "\n",
    "04/14/2021\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYm_W2VmV29Q"
   },
   "source": [
    "##Theme:\n",
    " “Adversarial Text Generation: Adversarial Machine Learning Applications in Text Analysis”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FO1KWsImV0qL"
   },
   "source": [
    "##Purpose:\n",
    "The purpose of this report is to...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yoao82RYVyPQ"
   },
   "source": [
    "##Project: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fa5hlsi4Vv2s"
   },
   "source": [
    "##(Hard/Soft)ware:\n",
    "**Google Colaboratory**\t\thttps://colab.research.google.com/\n",
    "**GPU**                     Python 3 Google Compute Engine backend\n",
    "**Github**                  https://github.com/eordanis/CIS-700/tree/main/Project/Milestone1/Milestone1_no_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tTAu6jxLVucS"
   },
   "source": [
    "##Resources:\n",
    "**Original Source Model:** \t\thttps://github.com/msc-acse/acse-9-independent-research-project-hk-97/\n",
    "**Modified Sources Model:** \thttps://github.com/eordanis/CIS-700/tree/main/Project/Milestone1/Milestone1_no_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_KWXYqJVrMc"
   },
   "source": [
    "##Data:\n",
    "**Kaggle**                  https://www.kaggle.com/datatattle/covid-19-nlp-text-classification\n",
    "The data for the selected project is setup as follows:\n",
    "\n",
    "...explain data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Afos897MVjpK"
   },
   "source": [
    "##Setup:\n",
    "Due to the heft of processor/gpu usage, it was deemed necessary to run the project in the Google Colaboratory.\n",
    "Original attempt to run was done via Pycharm IDE Professional Edition with Anaconda derived environments,\n",
    "however this proved too great of a strain on the accessible workstation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NEui79yMV-Qw"
   },
   "source": [
    "###Step 1\n",
    "A new Google Colaboratory workspace was setup, titled “Milestone1”. This workspace was run using the hosted runtime environment. This document is the current document being read.\n",
    "\n",
    "In order to run against provided code base, it was necessary to sync the colab workspace the github repository files as follows\n",
    "\n",
    "```\n",
    "from getpass import getpass\n",
    "import os\n",
    "user = getpass('github user')\n",
    "password = getpass('github password')\n",
    "os.environ['GITHUB_AUTH'] = user + ':' + password\n",
    "\n",
    "!git clone https://$GITHUB_AUTH@github.com/eordanis/CIS-700/\n",
    "```\n",
    "\n",
    "Running this command from the first cell in the workbook syncs the drive to the github repo location of project location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h7sLIljCoJQU"
   },
   "outputs": [],
   "source": [
    "# from getpass import getpass\n",
    "# import os\n",
    "# user = getpass('github user')\n",
    "# password = getpass('github password')\n",
    "# os.environ['GITHUB_AUTH'] = user + ':' + password\n",
    "\n",
    "# !git clone https://$GITHUB_AUTH@github.com/eordanis/CIS-700/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Step 2\n",
    "Now the directory was changed to the folder needed to run the project\n",
    "\n",
    "```\n",
    "        %cd CIS-700/Project/Milestone1/Milestone1_no_data\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %cd CIS-700/Project/Milestone1/Milestone1_no_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlyGK9vATpxl"
   },
   "source": [
    "###Step 3\n",
    "Now it was necessary to import and download any missing libraries the hosted colaborartoy runtime did not have readily available via the following commands: \n",
    "```\n",
    "         !pip install -r \"requirements.txt\"\n",
    "```\n",
    "Running this command from the next cell in the workbook installed the necessary libraries and at specified versions for the project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pV7IkP-kv-6q"
   },
   "outputs": [],
   "source": [
    "# !pip install -r \"requirements.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "###Step 4\n",
    "\n",
    "It is now required to load the necessary modules to run the project.\n",
    "We will import the Following:\n",
    "\n",
    "```\n",
    "from trainer import Trainer\n",
    "from gan import GAN\n",
    "from DataLoader import DataLoader\n",
    "from DataHandler import DataHandler\n",
    "from utils import create_directories\n",
    "import pandas as pd\n",
    "```\n",
    "\n",
    "These imports pull in our Trainer, GAN, DataLoader, DataHandler, and utils classes necessary for model, generator, and discriminator generation and trainings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from trainer import Trainer\n",
    "from GAN import GAN\n",
    "from DataLoader import DataLoader\n",
    "from DataHandler import DataHandler\n",
    "from utils import create_directories\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "toQoDwiqWjvh"
   },
   "source": [
    "###Step 5\n",
    "\n",
    "We must now Load and Prepare the Data\n",
    "\n",
    "The requested features and activities are also determined here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "features = [\"userAcceleration.x\", \"userAcceleration.y\", \"userAcceleration.z\"]\n",
    "act_labels = [\"std\"]#,\"ups\",\"wlk\", \"jog\", \"sit\", \"std\"]\n",
    "\n",
    "\n",
    "train_loader = DataLoader()\n",
    "train_ts, test_ts,num_features, num_act_labels = train_loader.extract_from_csv(features, act_labels, verbose=True)\n",
    "\n",
    "\n",
    "train_data, act_train_labels = train_loader.time_series_to_section(train_ts.copy(),\n",
    "                                                                   num_act_labels,\n",
    "                                                                   sliding_window_size=200,\n",
    "                                                                   step_size_of_sliding_window=10)\n",
    "\n",
    "test_data, act_test_labels = train_loader.time_series_to_section(test_ts.copy(),\n",
    "                                                                 num_act_labels,\n",
    "                                                                 sliding_window_size=200,\n",
    "                                                                 step_size_of_sliding_window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"TextData/coronavirus_tweets_nlp/Corona_NLP_train.csv\", encoding=\"ISO-8859-1\")\n",
    "test_data = pd.read_csv(\"TextData/coronavirus_tweets_nlp/Corona_NLP_test.csv\")\n",
    "\n",
    "orig_tweet_train = train_data[\"OriginalTweet\"];\n",
    "# print(\"--- Shape of orig_tweet train Data:\", orig_tweet_train.shape)\n",
    "encoded_train = []\n",
    "# for i in range(orig_tweet_train.shape[0]):\n",
    "for i in range(5):\n",
    "#     np.append(encoded_train, orig_tweet_train[i].encode('utf8'))\n",
    "    encoded_train.append(list(orig_tweet_train[i].encode('utf8')))\n",
    "encoded_train_np = np.asarray(encoded_train)\n",
    "\n",
    "# decoded_train = []\n",
    "# for i in range(len(encoded_train)):\n",
    "#     decoded_train.append(encoded_train[i].decode('ISO-8859-1'))\n",
    "# decoded_train_np = np.asarray(decoded_train)\n",
    "\n",
    "orig_tweet_test = test_data[\"OriginalTweet\"];\n",
    "# print(\"--- Shape of orig_tweet train Data:\", orig_tweet_train.shape)\n",
    "encoded_test = []\n",
    "# for i in range(orig_tweet_test.shape[0]):\n",
    "for i in range(5):\n",
    "    encoded_test.append(list(orig_tweet_test[i].encode('utf8')))\n",
    "encoded_test_np = np.asarray(encoded_test)\n",
    "    \n",
    "# decoded_test = []\n",
    "# for i in range(len(encoded_test)):\n",
    "#     decoded_test.append(encoded_test[i].decode('ISO-8859-1'))\n",
    "# decoded_test_np = np.asarray(decoded_test)\n",
    "\n",
    "\n",
    "print(\"---Data is successfully loaded\")\n",
    "# handler = DataHandler(encoded_train_np, encoded_test_np)\n",
    "# norm_train = handler.normalise(\"train\")\n",
    "print(\"test\")\n",
    "# norm_train = (encoded_train_np - np.mean(encoded_train_np)) / np.std(encoded_train_np)\n",
    "# print(encoded_train_np[0])\n",
    "# norm_test = handler.normalise(\"test\")\n",
    "\n",
    "print(\"--- Shape of Training Data:\", train_data.shape)\n",
    "print(\"--- Shape of Test Data:\", test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(encoded_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Step 6\n",
    "\n",
    "Here, we will be defining the experiment baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "expt_name = \"test\"\n",
    "\n",
    "create_directories(expt_name)\n",
    "gan_ = GAN(encoded_train_np.shape)\n",
    "trainer_ = Trainer(gan_, expt_name)\n",
    "trainer_.train_gan(epochs=20000, batch_size=128, sample_interval=10, train_data=encoded_train_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7p_f6JXcW5EH"
   },
   "source": [
    "##Process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41x987LZW7eY"
   },
   "source": [
    "##Metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wcKN7nQSYBkG"
   },
   "source": [
    "##Models\n",
    "For this report, the GAN model was run ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGfLkFFKYGdJ"
   },
   "source": [
    "##Testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Vb97-8TpM0W"
   },
   "source": [
    "###Data Comparision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUwxdQptsoLi",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Reference\n",
    "[1] Git-hub. https://github.com/msc-acse/acse-9-independent-research-project-hk-97/\n",
    "[2] Git-hub. https://github.com/eordanis/CIS-700/tree/main/Project/Milestone1/Milestone1_no_data\n",
    "[3] Kaggle.  https://www.kaggle.com/datatattle/covid-19-nlp-text-classification\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#PDF/HTML conversion of notebook\n",
    "!apt-get install texlive texlive-xetex texlive-latex-extra pandoc\n",
    "!pip install pypandoc\n",
    "!jupyter nbconvert --to PDF \"Milestone1.ipynb\"\n",
    "!jupyter nbconvert --to HTML \"Milestone1.ipynb\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1boyV7fUaPPl"
   },
   "source": [
    "#PDF/HTML conversion of notebook\n",
    "!apt-get install texlive texlive-xetex texlive-latex-extra pandoc\n",
    "!pip install pypandoc\n",
    "!jupyter nbconvert --to PDF \"Milestone1.ipynb\"\n",
    "!jupyter nbconvert --to HTML \"Milestone1.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C1HgP-RGn2yr"
   },
   "outputs": [],
   "source": [
    "#PDF/HTML conversion of notebook\n",
    "!apt-get install texlive texlive-xetex texlive-latex-extra pandoc\n",
    "!pip install pypandoc\n",
    "!jupyter nbconvert --to PDF \"Milestone1.ipynb\"\n",
    "!jupyter nbconvert --to HTML \"Milestone1.ipynb\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM37WU41p2D3YebeEjpw9OZ",
   "collapsed_sections": [],
   "name": "Assignment1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}